{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee19835-a989-4020-9fe6-3d656840b1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.dataset import VideoDataset\n",
    "from utils.earlystopping import EarlyStopping\n",
    "from utils.function import make_datapath_list\n",
    "from utils.model import HBM\n",
    "from utils.transform import VideoTransform\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "\n",
    "from pytorch_metric_learning.losses import ArcFaceLoss\n",
    "\n",
    "# 乱数のシードを設定\n",
    "torch.manual_seed(1234)\n",
    "np.random.seed(1234)\n",
    "random.seed(1234)\n",
    "\n",
    "device = \"cuda:1\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# train, test, validation\n",
    "classes = ('5_A',  # 16\n",
    "           '5_B',  # 17\n",
    "           '5_C',  # 18\n",
    "           '5_D',  # 19\n",
    "           '6_A',  # 20\n",
    "           '6_B',  # 21\n",
    "           '6_C',  # 22\n",
    "           '6_D',  # 23\n",
    "           '7_A',  # 24\n",
    "           '7_B',  # 25\n",
    "           '7_C',  # 26\n",
    "           '7_D',  # 27\n",
    "           '8_A',  # 28\n",
    "           '8_B',  # 29\n",
    "           '8_C',  # 30\n",
    "           '8_D',  # 31\n",
    "           '9_A',  # 32\n",
    "           '9_B',  # 33\n",
    "           '9_C',  # 34\n",
    "           '9_D',  # 35\n",
    "           '10_A', # 36\n",
    "           '10_B', # 37\n",
    "           '10_C', # 38\n",
    "           '10_D') # 39\n",
    "\n",
    "# unknown\n",
    "unknown_classes = ('1_A',  # 0\n",
    "                   '1_B',  # 1\n",
    "                   '1_C',  # 2\n",
    "                   '1_D',  # 3\n",
    "                   '2_A',  # 4\n",
    "                   '2_B',  # 5\n",
    "                   '2_C',  # 6\n",
    "                   '2_D',  # 7\n",
    "                   '3_A',  # 8\n",
    "                   '3_B',  # 9\n",
    "                   '3_C',  # 10\n",
    "                   '3_D',  # 11\n",
    "                   '4_A',  # 12\n",
    "                   '4_B',  # 13\n",
    "                   '4_C',  # 14\n",
    "                   '4_D')  # 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47fb1868-30f8-46c0-8273-62a3d69a918e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train セットアップ ファインチューニングあり\n",
    "batch_size = 16\n",
    "num_classes = len(classes)\n",
    "embedding_size = 256\n",
    "\n",
    "# ファイルパスのリストを作成\n",
    "root_path = './data/unknown_1_to_4/'\n",
    "train_video_list = make_datapath_list(os.path.join(root_path, \"Train\"))\n",
    "val_video_list = make_datapath_list(os.path.join(root_path, \"Validation\"))\n",
    "\n",
    "\n",
    "# 前処理の設定\n",
    "resize = 96\n",
    "ccrop_size = 96\n",
    "rcrop_size = (96, 120)\n",
    "mean, std = [0.449], [0.226]\n",
    "# mean, std = [0.485, 0.456, 0.406], [0.229, 0.224, 0.225]\n",
    "video_transform = VideoTransform(resize, ccrop_size, rcrop_size, mean, std)\n",
    "\n",
    "\n",
    "# video_id label_id 辞書 (train)\n",
    "train_csv_path = os.path.join(root_path, \"Train.csv\")\n",
    "train_df = pd.read_csv(train_csv_path)\n",
    "train_videoid_labelid_dict = dict(train_df[[\"video_id\", \"label_id\"]].to_numpy())\n",
    "\n",
    "# video_id label_id 辞書 (val)\n",
    "val_csv_path = os.path.join(root_path, \"Validation.csv\")\n",
    "val_df = pd.read_csv(val_csv_path)\n",
    "val_videoid_labelid_dict = dict(val_df[[\"video_id\", \"label_id\"]].to_numpy())\n",
    "\n",
    "\n",
    "# データセットの作成\n",
    "train_dataset = VideoDataset(train_video_list, train_videoid_labelid_dict, num_segments=32,\n",
    "                             phase=\"train\", transform=video_transform, img_tmpl=\"{:05d}.jpg\", random_frame=True)\n",
    "val_dataset = VideoDataset(val_video_list, val_videoid_labelid_dict, num_segments=32,\n",
    "                           phase=\"val\", transform=video_transform, img_tmpl=\"{:05d}.jpg\", random_frame=False)\n",
    "\n",
    "\n",
    "# データローダーの作成\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "dataloaders_dict = {\"train\": train_dataloader, \"val\": val_dataloader}\n",
    "\n",
    "\n",
    "loss_func = ArcFaceLoss(num_classes, embedding_size).to(device)\n",
    "\n",
    "# model読み込み\n",
    "model = HBM().to(device)\n",
    "load_model_path = './weights/pretrained_HBM_model.pth'\n",
    "# load_model_weights = torch.load(load_model_path, map_location={'cuda:2': 'cpu'})\n",
    "load_model_weights = torch.load(load_model_path)\n",
    "model.load_state_dict(load_model_weights)\n",
    "\n",
    "\n",
    "# ファインチューニングで学習させるパラメータを、変数params_to_updateの1～3に格納する\n",
    "params_to_update_1 = []\n",
    "params_to_update_2 = []\n",
    "params_to_update_3 = []\n",
    "\n",
    "# 学習させる層のパラメータ名を指定\n",
    "update_param_names_1 = [\"eco_2d\"]\n",
    "update_param_names_2 = [\"eco_3d\"]\n",
    "update_param_names_3 = [\"eco_left.fc_final.weight\", \"eco_left.fc_final.bias\",\n",
    "                        \"eco_right.fc_final.weight\", \"eco_right.fc_final.bias\"]\n",
    "\n",
    "# パラメータごとに各リストに格納する\n",
    "for name, param in model.named_parameters():\n",
    "    if update_param_names_1[0] in name:\n",
    "        param.requires_grad = True\n",
    "        params_to_update_1.append(param)\n",
    "        print(\"params_to_update_1に格納：\", name)\n",
    "\n",
    "    elif update_param_names_2[0] in name:\n",
    "        param.requires_grad = True\n",
    "        params_to_update_2.append(param)\n",
    "        print(\"params_to_update_2に格納：\", name)\n",
    "\n",
    "    elif name in update_param_names_3:\n",
    "        param.requires_grad = True\n",
    "        params_to_update_3.append(param)\n",
    "        print(\"params_to_update_3に格納：\", name)\n",
    "\n",
    "    else:\n",
    "        param.requires_grad = False\n",
    "        print(\"勾配計算なし。学習しない：\", name)\n",
    "\n",
    "\n",
    "optimizer = optim.Adam([{'params': params_to_update_1, 'lr': 1e-5},\n",
    "                        {'params': params_to_update_2, 'lr': 5e-5},\n",
    "                        {'params': params_to_update_3, 'lr': 1e-4},\n",
    "                        {'params': loss_func.parameters(), 'lr': 1e-4}])\n",
    "\n",
    "\n",
    "# モデルの学習\n",
    "train_losses, val_losses = train_model(model, loss_func, device, dataloaders_dict, optimizer, num_epochs)\n",
    "\n",
    "\n",
    "# loss の保存\n",
    "date = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "outfile = 'loss_{}.cpt'.format(date)\n",
    "torch.save({'train_losses': train_losses, 'val_losses': val_losses}, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba6f0f0-9c0b-4d66-b7b3-4407c094767a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test セットアップ\n",
    "# device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "num_classes = len(classes)\n",
    "embedding_size = 256\n",
    "\n",
    "# model読み込み\n",
    "model = HBM().to(device)\n",
    "load_model_path = './weights/checkpoint_fine_unknown_1_and_2_aug_10-data_model_20220205_173510.pth'\n",
    "load_model_weights = torch.load(load_model_path, map_location=device)\n",
    "model.load_state_dict(load_model_weights)\n",
    "\n",
    "# loss_func読み込み\n",
    "loss_func = ArcFaceLoss(num_classes, embedding_size).to(device)\n",
    "load_loss_func_path = './weights/checkpoint_fine_unknown_1_and_2_aug_10-data_loss_func_20220205_173510.pth'\n",
    "load_loss_func_weights = torch.load(load_loss_func_path, map_location=device)\n",
    "loss_func.load_state_dict(load_loss_func_weights)\n",
    "\n",
    "\n",
    "# ファイルパスのリストを作成 (test)\n",
    "# root_path = './data/'\n",
    "# root_path = './data/all_data/'\n",
    "root_path = './data/unknown_1_and_2/'\n",
    "test_video_list = make_datapath_list(os.path.join(root_path, \"Test\"))\n",
    "# test_video_list = make_datapath_list(os.path.join(root_path, \"Unknown\"))\n",
    "\n",
    "\n",
    "# 前処理の設定\n",
    "resize = 96\n",
    "ccrop_size = 96\n",
    "rcrop_size = (96, 120)\n",
    "mean, std = [0.449], [0.226]\n",
    "# mean, std = [0.485, 0.456, 0.406], [0.229, 0.224, 0.225]\n",
    "video_transform = VideoTransform(resize, ccrop_size, rcrop_size, mean, std)\n",
    "\n",
    "\n",
    "# video_id label_id 辞書 (test)\n",
    "test_csv_path = os.path.join(root_path, \"Test.csv\")\n",
    "# test_csv_path = './data/Unknown.csv'\n",
    "test_df = pd.read_csv(test_csv_path)\n",
    "test_videoid_labelid_dict = dict(test_df[[\"video_id\", \"label_id\"]].to_numpy())\n",
    "\n",
    "\n",
    "# データセットの作成\n",
    "test_dataset = VideoDataset(test_video_list, test_videoid_labelid_dict, num_segments=32,\n",
    "                           phase=\"val\", transform=video_transform, img_tmpl=\"{:05d}.jpg\")\n",
    "\n",
    "\n",
    "# データローダーの作成\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=96, shuffle=False) # test\n",
    "# test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=120, shuffle=False) # unknown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64f8a76-0d6b-4404-9c52-131cff24d4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unknown セットアップ\n",
    "num_classes = len(classes)\n",
    "embedding_size = 256\n",
    "\n",
    "\n",
    "# ファイルパスのリストを作成 (unknown)\n",
    "# root_path = './data/'\n",
    "root_path = './data/unknown_1_and_2/'\n",
    "unknown_video_list = make_datapath_list(os.path.join(root_path, \"Unknown\"))\n",
    "\n",
    "\n",
    "# 前処理の設定\n",
    "resize = 96\n",
    "ccrop_size = 96\n",
    "rcrop_size = (96, 120)\n",
    "mean, std = [0.449], [0.226]\n",
    "# mean, std = [0.485, 0.456, 0.406], [0.229, 0.224, 0.225]\n",
    "video_transform = VideoTransform(resize, ccrop_size, rcrop_size, mean, std)\n",
    "\n",
    "\n",
    "# video_id label_id 辞書 (unknown)\n",
    "unknown_csv_path = os.path.join(root_path, \"Unknown.csv\")\n",
    "unknown_df = pd.read_csv(unknown_csv_path)\n",
    "unknown_videoid_labelid_dict = dict(unknown_df[[\"video_id\", \"label_id\"]].to_numpy())\n",
    "\n",
    "\n",
    "# データセットの作成\n",
    "unknown_dataset = VideoDataset(unknown_video_list, unknown_videoid_labelid_dict, num_segments=32,\n",
    "                               phase=\"val\", transform=video_transform, img_tmpl=\"{:05d}.jpg\")\n",
    "\n",
    "\n",
    "# データローダーの作成\n",
    "unknown_dataloader = torch.utils.data.DataLoader(unknown_dataset, batch_size=120, shuffle=False) # unknown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a47024-c9b6-4cee-b07d-1d7c87ef5cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test and unknown セットアップ デフォルトのラベルを使用する場合\n",
    "# ファイルパスのリストを作成 \n",
    "# root_path = './data/'\n",
    "root_path = './data/unknown_1_and_2/'\n",
    "test_video_list = make_datapath_list(os.path.join(root_path, \"Test\"))\n",
    "unknown_video_list = make_datapath_list(os.path.join(root_path, \"Unknown\"))\n",
    "\n",
    "\n",
    "# 前処理の設定\n",
    "resize = 96\n",
    "ccrop_size = 96\n",
    "rcrop_size = (96, 120)\n",
    "mean, std = [0.449], [0.226]\n",
    "# mean, std = [0.485, 0.456, 0.406], [0.229, 0.224, 0.225]\n",
    "video_transform = VideoTransform(resize, ccrop_size, rcrop_size, mean, std)\n",
    "\n",
    "\n",
    "# video_id label_id 辞書 (test)\n",
    "test_csv_path = os.path.join(root_path, \"Test_default.csv\")\n",
    "test_df = pd.read_csv(test_csv_path)\n",
    "test_videoid_labelid_dict = dict(test_df[[\"video_id\", \"label_id\"]].to_numpy())\n",
    "\n",
    "# video_id label_id 辞書 (unknown)\n",
    "unknown_csv_path = os.path.join(root_path, \"Unknown_default.csv\")\n",
    "unknown_df = pd.read_csv(unknown_csv_path)\n",
    "unknown_videoid_labelid_dict = dict(unknown_df[[\"video_id\", \"label_id\"]].to_numpy())\n",
    "\n",
    "\n",
    "# データセットの作成\n",
    "test_dataset = VideoDataset(test_video_list, test_videoid_labelid_dict, num_segments=32,\n",
    "                            phase=\"val\", transform=video_transform, img_tmpl=\"{:05d}.jpg\")\n",
    "unknown_dataset = VideoDataset(unknown_video_list, unknown_videoid_labelid_dict, num_segments=32,\n",
    "                               phase=\"val\", transform=video_transform, img_tmpl=\"{:05d}.jpg\")\n",
    "\n",
    "\n",
    "# データローダーの作成\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=96, shuffle=False) # test\n",
    "unknown_dataloader = torch.utils.data.DataLoader(unknown_dataset, batch_size=120, shuffle=False) # unknown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df24de7-bd4d-49ab-b272-47e888e69dac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd8ec28-8adc-4144-82f7-ecc66823bdd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test data の精度\n",
    "import torch.nn.functional as F\n",
    "\n",
    "W_cos = loss_func.state_dict()['W']\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "class_correct = list(0. for i in range(num_classes))\n",
    "class_total = list(0. for i in range(num_classes))\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_dataloader:\n",
    "#         inputs, labels = inputs.to(device), labels.to(device)\n",
    "        inputs, labels = [side_inputs.to(device) for side_inputs in inputs], labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        cosine = F.linear(F.normalize(outputs), F.normalize(W_cos.T))\n",
    "        _, predicted = torch.max(cosine, 1)\n",
    "        \n",
    "        c = (predicted == labels).squeeze()\n",
    "        total += labels.size(0)\n",
    "        correct += c.sum().item()\n",
    "        \n",
    "        for i in range(labels.size(0)):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "print('Accuracy: %d %%' % (100 * correct / total))\n",
    "\n",
    "for i in range(num_classes):\n",
    "    print('Accuracy of %s : %2d %%' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa09e61-8afe-4761-b67c-4d2294010706",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss の推移\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# loss の読み込み\n",
    "cptfile = 'loss_fine_unknown_1_and_2_aug_10-data_20220205_175701.cpt'\n",
    "# cptfile = 'loss_fine_unknown_1_and_2_10-data_20220112_033846.cpt'\n",
    "# cptfile = 'loss_fine_unknown_1_and_2_augmiss_10-data_20220204_133540.cpt'\n",
    "cpt = torch.load(cptfile)\n",
    "train_losses = cpt['train_losses']\n",
    "val_losses = cpt['val_losses']\n",
    "\n",
    "# plot learning curve\n",
    "plt.figure()\n",
    "plt.plot(range(len(train_losses)), train_losses, 'r-', label='train_loss')\n",
    "plt.plot(range(len(val_losses[:-1])), val_losses[:-1], 'b-', label='val_loss')\n",
    "plt.legend()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.grid()\n",
    "date = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "outfile = 'loss_output_{}.png'.format(date)\n",
    "plt.savefig(outfile)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6245a80-0877-4913-b41e-853c85cb8630",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_tSNE(outputs, labels, perplexity):\n",
    "    # 特徴量ベクトル\n",
    "    embeddings = outputs.detach().cpu().numpy()\n",
    "    embeddings = embeddings.reshape(embeddings.shape[0], embeddings.shape[1])\n",
    "    lebels_tSNE = labels.detach().cpu().numpy()\n",
    "    \n",
    "    # ２次元に埋め込み\n",
    "    tSNE_metrics = TSNE(n_components=2, random_state=0, perplexity=perplexity).fit_transform(embeddings)\n",
    "    \n",
    "    # 同じラベルが近くに分布しているか\n",
    "    plt.scatter(tSNE_metrics[:, 0], tSNE_metrics[:, 1], c=lebels_tSNE)\n",
    "    plt.colorbar()\n",
    "    date = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "#     outfile = 't-SNE_label_{}_perplexity={}.eps'.format(date, perplexity)\n",
    "    outfile = 't-SNE_label_{}_perplexity={}.png'.format(date, perplexity)\n",
    "    plt.savefig(outfile)\n",
    "    plt.show()\n",
    "    \n",
    "    # 同じジェスチャが近くに分布しているか\n",
    "    labels_gesture = np.where(lebels_tSNE%4==0, 0, lebels_tSNE)\n",
    "    labels_gesture = np.where(labels_gesture%4==1, 1, labels_gesture)\n",
    "    labels_gesture = np.where(labels_gesture%4==2, 2, labels_gesture)\n",
    "    labels_gesture = np.where(labels_gesture%4==3, 3, labels_gesture)\n",
    "    plt.scatter(tSNE_metrics[:, 0], tSNE_metrics[:, 1], c=labels_gesture)\n",
    "    plt.colorbar()\n",
    "    date = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "#     outfile = 't-SNE_gesture_{}_perplexity={}.eps'.format(date, perplexity)\n",
    "    outfile = 't-SNE_gesture_{}_perplexity={}.png'.format(date, perplexity)\n",
    "    plt.savefig(outfile)\n",
    "    plt.show()\n",
    "    \n",
    "    # 同じユーザが近くに分布しているか\n",
    "    labels_user = np.where(lebels_tSNE<4, 0, lebels_tSNE)\n",
    "    labels_user = np.where((lebels_tSNE>=4) & (lebels_tSNE<8), 1, labels_user)\n",
    "    labels_user = np.where((lebels_tSNE>=8) & (lebels_tSNE<12), 2, labels_user)\n",
    "    labels_user = np.where((lebels_tSNE>=12) & (lebels_tSNE<16), 3, labels_user)\n",
    "    labels_user = np.where((lebels_tSNE>=16) & (lebels_tSNE<20), 4, labels_user)\n",
    "    labels_user = np.where((lebels_tSNE>=20) & (lebels_tSNE<24), 5, labels_user)\n",
    "    labels_user = np.where((lebels_tSNE>=24) & (lebels_tSNE<28), 6, labels_user)\n",
    "    labels_user = np.where((lebels_tSNE>=28) & (lebels_tSNE<32), 7, labels_user)\n",
    "    labels_user = np.where((lebels_tSNE>=32) & (lebels_tSNE<36), 8, labels_user)\n",
    "    labels_user = np.where((lebels_tSNE>=36) & (lebels_tSNE<40), 9, labels_user)\n",
    "    plt.scatter(tSNE_metrics[:, 0], tSNE_metrics[:, 1], c=labels_user)\n",
    "    plt.colorbar()\n",
    "    date = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "#     outfile = 't-SNE_user_{}_perplexity={}.eps'.format(date, perplexity)\n",
    "    outfile = 't-SNE_user_{}_perplexity={}.png'.format(date, perplexity)\n",
    "    plt.savefig(outfile)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e4d86c-0151-4c13-9b10-e8356bc1fc0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_EER(x_p, x_n, data_group=\"all\"):\n",
    "    print(x_p.shape, x_n.shape)\n",
    "#     print(x_p)\n",
    "#     print(x_n)\n",
    "    num_far = x_n.shape[0]\n",
    "    num_frr = x_p.shape[0]\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.hist(x_n, bins=50, alpha=0.5, range=(-1, 1), label='nagative pair')\n",
    "    ax.hist(x_p, bins=50, alpha=0.5, range=(-1, 1), label='positive pair')\n",
    "#     ax.hist(x_n, bins=50, range=(-1, 1), label='nagative pair')\n",
    "#     ax.hist(x_p, bins=50, range=(-1, 1), label='positive pair')\n",
    "    ax.set_title('all pair')\n",
    "    ax.set_xlabel('cos similarity')\n",
    "    plt.legend(loc='upper left')\n",
    "    date = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    outfile = 'cos_similarity_{}_{}.png'.format(data_group, date)\n",
    "    plt.savefig(outfile)\n",
    "    plt.show()\n",
    "    \n",
    "    far = []\n",
    "    for i in range(2001):\n",
    "        num = 0\n",
    "        \n",
    "        for x in x_n:\n",
    "            if x > (-1 + 0.001*i):\n",
    "                num+=1\n",
    "        far.append(num)\n",
    "\n",
    "    frr = []\n",
    "    for i in range(2001):\n",
    "        num = 0\n",
    "    \n",
    "        for x in x_p:\n",
    "            if x < (-1 + 0.001*i):\n",
    "                num+=1\n",
    "        frr.append(num)\n",
    "\n",
    "    far = np.array(far)\n",
    "    frr = np.array(frr)\n",
    "#     np.set_printoptions(threshold=np.inf)\n",
    "#     print('far', far)\n",
    "#     print('frr', frr)\n",
    "    \n",
    "    threshold = [-1 + 0.001*i for i in range(2001)]\n",
    "    threshold = np.array(threshold)\n",
    "    \n",
    "#     for i in range(2001):\n",
    "#         print(-1 + 0.001*i, \"frr\", frr[i]/num_frr)\n",
    "#         print(-1 + 0.001*i, \"far\", far[i]/num_far)\n",
    "#         print(\"________________\")\n",
    "    \n",
    "    plt.plot(threshold,frr/num_frr,'--b')\n",
    "    plt.plot(threshold,far/num_far,'--r')\n",
    "    plt.xlabel('threshold')\n",
    "    plt.title('FAR and FRR')\n",
    "    plt.axis([-1, 1, -0.005, 1.005])\n",
    "    date = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "#     outfile = 'FAR and FRR_{}_{}.eps'.format(data_group, date)\n",
    "    outfile = 'FAR and FRR_{}_{}.png'.format(data_group, date)\n",
    "    plt.savefig(outfile)\n",
    "    plt.show()\n",
    "    \n",
    "    EER = -1\n",
    "    EER_FAR = -1\n",
    "    EER_FRR = -1\n",
    "    EER_T = []\n",
    "    FAR_FRR_0 = -1\n",
    "    FAR_FRR_0_T = []\n",
    "    FRR_FAR_0 = -1\n",
    "    FRR_FAR_0_T = []\n",
    "    \n",
    "    if x_n.max() < x_p.min():\n",
    "        # EER is 0\n",
    "        for i in range(2001):\n",
    "            a = frr[i]/num_frr\n",
    "            b = far[i]/num_far\n",
    "            if a == b:\n",
    "                EER_T.append(i)\n",
    "        EER = 0\n",
    "        EER_FAR = 0\n",
    "        EER_FRR = 0\n",
    "        FAR_FRR_0 = 0\n",
    "        FRR_FAR_0 = 0\n",
    "        FAR_FRR_0_T = EER_T\n",
    "        FRR_FAR_0_T = EER_T\n",
    "        return EER, EER_FAR, EER_FRR, EER_T, FAR_FRR_0, FAR_FRR_0_T, FRR_FAR_0, FRR_FAR_0_T\n",
    "    else:\n",
    "        # EER is not 0\n",
    "        for i in range(2001):\n",
    "            a = frr[i]/num_frr\n",
    "            b = far[i]/num_far\n",
    "            if a > b and EER == -1:\n",
    "                EER_T.append(i)\n",
    "                EER = frr[i]/num_frr\n",
    "                EER_FAR = far[i]/num_far\n",
    "                EER_FRR = frr[i]/num_frr\n",
    "            if a > 0 and FAR_FRR_0 == -1:\n",
    "                FAR_FRR_0_T.append(i-1)\n",
    "                FAR_FRR_0 = far[i-1]/num_far\n",
    "            if b == 0 and FRR_FAR_0 == -1:\n",
    "                FRR_FAR_0_T.append(i)\n",
    "                FRR_FAR_0 = frr[i]/num_frr\n",
    "        return EER, EER_FAR, EER_FRR, EER_T, FAR_FRR_0, FAR_FRR_0_T, FRR_FAR_0, FRR_FAR_0_T\n",
    "    \n",
    "\n",
    "def display_info(EER, EER_FAR, EER_FRR, EER_T, FAR_FRR_0, FAR_FRR_0_T, FRR_FAR_0, FRR_FAR_0_T):\n",
    "    if len(EER_T) > 1:\n",
    "        # EER is 0\n",
    "        print(\"EER:\", EER)\n",
    "        print(\"EER_FAR:\", EER_FAR)\n",
    "        print(\"EER_FRR:\", EER_FRR)\n",
    "        print(\"EER_T_min:\", EER_T[0], -1 + 0.001*EER_T[0])\n",
    "        print(\"EER_T_max:\", EER_T[-1], -1 + 0.001*EER_T[-1])\n",
    "        print(\"FAR_FRR_0:\", FAR_FRR_0)\n",
    "        print(\"FRR_FAR_0:\", FRR_FAR_0)\n",
    "        print(\"FAR_FRR_0_T and FRR_FAR_0_T are the same as EER_T\")\n",
    "    else:\n",
    "        # EER is not 0\n",
    "        print(\"EER:\", EER)\n",
    "        print(\"EER_FAR:\", EER_FAR)\n",
    "        print(\"EER_FRR:\", EER_FRR)\n",
    "        print(\"EER_T:\", EER_T[0], -1 + 0.001*EER_T[0])\n",
    "        print(\"FAR_FRR_0:\", FAR_FRR_0)\n",
    "        print(\"FAR_FRR_0_T:\", FAR_FRR_0_T[0], -1 + 0.001*FAR_FRR_0_T[0])\n",
    "        print(\"FRR_FAR_0:\", FRR_FAR_0)\n",
    "        print(\"FRR_FAR_0_T:\", FRR_FAR_0_T[0], -1 + 0.001*FRR_FAR_0_T[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05340d85-e29c-48dd-a96f-92b8031e40b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exp_1\n",
    "from utils.dataset import VideoDataset\n",
    "from utils.earlystopping import EarlyStopping\n",
    "from utils.function import make_datapath_list\n",
    "from utils.model import HBM\n",
    "from utils.transform import VideoTransform\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "\n",
    "from pytorch_metric_learning.losses import ArcFaceLoss\n",
    "\n",
    "# 乱数のシードを設定\n",
    "torch.manual_seed(1234)\n",
    "np.random.seed(1234)\n",
    "random.seed(1234)\n",
    "\n",
    "device = \"cuda:1\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# all\n",
    "classes = ('1_A',  # 0\n",
    "           '1_B',  # 1\n",
    "           '1_C',  # 2\n",
    "           '1_D',  # 3\n",
    "           '2_A',  # 4\n",
    "           '2_B',  # 5\n",
    "           '2_C',  # 6\n",
    "           '2_D',  # 7\n",
    "           '3_A',  # 8\n",
    "           '3_B',  # 9\n",
    "           '3_C',  # 10\n",
    "           '3_D',  # 11\n",
    "           '4_A',  # 12\n",
    "           '4_B',  # 13\n",
    "           '4_C',  # 14\n",
    "           '4_D',  # 15\n",
    "           '5_A',  # 16\n",
    "           '5_B',  # 17\n",
    "           '5_C',  # 18\n",
    "           '5_D',  # 19\n",
    "           '6_A',  # 20\n",
    "           '6_B',  # 21\n",
    "           '6_C',  # 22\n",
    "           '6_D',  # 23\n",
    "           '7_A',  # 24\n",
    "           '7_B',  # 25\n",
    "           '7_C',  # 26\n",
    "           '7_D',  # 27\n",
    "           '8_A',  # 28\n",
    "           '8_B',  # 29\n",
    "           '8_C',  # 30\n",
    "           '8_D',  # 31\n",
    "           '9_A',  # 32\n",
    "           '9_B',  # 33\n",
    "           '9_C',  # 34\n",
    "           '9_D',  # 35\n",
    "           '10_A', # 36\n",
    "           '10_B', # 37\n",
    "           '10_C', # 38\n",
    "           '10_D') # 39\n",
    "\n",
    "\n",
    "# test セットアップ\n",
    "num_classes = len(classes)\n",
    "embedding_size = 256\n",
    "\n",
    "# model読み込み\n",
    "model = HBM().to(device)\n",
    "load_model_path = './weights/checkpoint_fine_all_data_aug_10-data_model_20220205_183047.pth'\n",
    "load_model_weights = torch.load(load_model_path, map_location=device)\n",
    "model.load_state_dict(load_model_weights)\n",
    "\n",
    "# loss_func読み込み\n",
    "loss_func = ArcFaceLoss(num_classes, embedding_size).to(device)\n",
    "load_loss_func_path = './weights/checkpoint_fine_all_data_aug_10-data_loss_func_20220205_183047.pth'\n",
    "load_loss_func_weights = torch.load(load_loss_func_path, map_location=device)\n",
    "loss_func.load_state_dict(load_loss_func_weights)\n",
    "\n",
    "\n",
    "# ファイルパスのリストを作成 (test)\n",
    "# root_path = './data/'\n",
    "root_path = './data/all_data/'\n",
    "test_video_list = make_datapath_list(os.path.join(root_path, \"Test\"))\n",
    "\n",
    "\n",
    "# 前処理の設定\n",
    "resize = 96\n",
    "ccrop_size = 96\n",
    "rcrop_size = (96, 120)\n",
    "mean, std = [0.449], [0.226]\n",
    "# mean, std = [0.485, 0.456, 0.406], [0.229, 0.224, 0.225]\n",
    "video_transform = VideoTransform(resize, ccrop_size, rcrop_size, mean, std)\n",
    "\n",
    "\n",
    "# video_id label_id 辞書 (test)\n",
    "test_csv_path = os.path.join(root_path, \"Test.csv\")\n",
    "test_df = pd.read_csv(test_csv_path)\n",
    "test_videoid_labelid_dict = dict(test_df[[\"video_id\", \"label_id\"]].to_numpy())\n",
    "\n",
    "\n",
    "# データセットの作成\n",
    "test_dataset = VideoDataset(test_video_list, test_videoid_labelid_dict, num_segments=32,\n",
    "                           phase=\"val\", transform=video_transform, img_tmpl=\"{:05d}.jpg\", random_frame=False)\n",
    "\n",
    "\n",
    "# データローダーの作成\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=120, shuffle=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# t-SNE, FAR, FRR, EER, cos\n",
    "model.eval()\n",
    "perplexity = 20\n",
    "W_cos = loss_func.state_dict()['W']\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_dataloader:\n",
    "        inputs, labels = [side_inputs.to(device) for side_inputs in inputs], labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        # t-SNEで２次元にプロット\n",
    "        plot_tSNE(outputs, labels, perplexity)\n",
    "        \n",
    "        cosine = F.linear(F.normalize(outputs), F.normalize(W_cos.T))\n",
    "        \n",
    "        # EER all\n",
    "        x_p_all = cosine[torch.arange(labels.size(0)), labels].detach().cpu().numpy()\n",
    "        delete_index = [i*W_cos.size(1) + l for i, l in enumerate(labels.detach().cpu().numpy())]\n",
    "        x_n_all = np.delete(cosine.detach().cpu().numpy(), delete_index).reshape(labels.size(0), -1)\n",
    "        x_n_all = np.reshape(x_n_all, -1)\n",
    "        \n",
    "        print(\"x_n_mean:\", x_n_all.mean())\n",
    "        print(\"x_p_mean:\", x_p_all.mean())\n",
    "        \n",
    "        EER, EER_FAR, EER_FRR, EER_T, FAR_FRR_0, FAR_FRR_0_T, FRR_FAR_0, FRR_FAR_0_T = calculate_EER(x_p_all, x_n_all, data_group=\"all\")\n",
    "        display_info(EER, EER_FAR, EER_FRR, EER_T, FAR_FRR_0, FAR_FRR_0_T, FRR_FAR_0, FRR_FAR_0_T)\n",
    "\n",
    "        # EER gesture A, B, C and D\n",
    "        for i, X in enumerate((\"A\", \"B\", \"C\", \"D\")):\n",
    "            cosine_X = cosine[labels%4==i, :]\n",
    "            cosine_X = cosine_X[:, torch.arange(num_classes)%4==i]\n",
    "            \n",
    "            labels_X = labels[labels%4==i].detach().cpu().numpy()\n",
    "            labels_X = ((labels_X-i)/4).astype(np.int64)\n",
    "        \n",
    "            x_p_X = cosine_X[np.arange(labels_X.size), labels_X].detach().cpu().numpy()\n",
    "            delete_index = [j*int(W_cos.size(1)/4) + l for j, l in enumerate(labels_X)]\n",
    "            x_n_X = np.delete(cosine_X.detach().cpu().numpy(), delete_index).reshape(-1)\n",
    "            \n",
    "            print(\"____________________________________________________\")\n",
    "            \n",
    "            print(\"x_n_mean:\", x_n_X.mean())\n",
    "            print(\"x_p_mean:\", x_p_X.mean())\n",
    "            \n",
    "            EER, EER_FAR, EER_FRR, EER_T, FAR_FRR_0, FAR_FRR_0_T, FRR_FAR_0, FRR_FAR_0_T = calculate_EER(x_p_X, x_n_X, data_group=X)\n",
    "            display_info(EER, EER_FAR, EER_FRR, EER_T, FAR_FRR_0, FAR_FRR_0_T, FRR_FAR_0, FRR_FAR_0_T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82f8829-4b5e-40f8-a4cd-aaf5c58bf4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exp_2\n",
    "from utils.dataset import VideoDataset\n",
    "from utils.earlystopping import EarlyStopping\n",
    "from utils.function import make_datapath_list\n",
    "from utils.model import HBM\n",
    "from utils.transform import VideoTransform\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "\n",
    "from pytorch_metric_learning.losses import ArcFaceLoss\n",
    "\n",
    "# 乱数のシードを設定\n",
    "torch.manual_seed(1234)\n",
    "np.random.seed(1234)\n",
    "random.seed(1234)\n",
    "\n",
    "device = \"cuda:1\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# train, test, validation\n",
    "classes = ('1_A',  # 0\n",
    "           '1_B',  # 1\n",
    "           '1_C',  # 2\n",
    "           '1_D',  # 3\n",
    "           '2_A',  # 4\n",
    "           '2_B',  # 5\n",
    "           '2_C',  # 6\n",
    "           '2_D',  # 7\n",
    "           '3_A',  # 8\n",
    "           '3_B',  # 9\n",
    "           '3_C',  # 10\n",
    "           '3_D',  # 11\n",
    "           '4_A',  # 12\n",
    "           '4_B',  # 13\n",
    "           '4_C',  # 14\n",
    "           '4_D',  # 15\n",
    "           '5_A',  # 16\n",
    "           '5_B',  # 17\n",
    "           '5_C',  # 18\n",
    "           '5_D',  # 19\n",
    "           '6_A',  # 20\n",
    "           '6_B',  # 21\n",
    "           '6_C',  # 22\n",
    "           '6_D',  # 23\n",
    "           '7_A',  # 24\n",
    "           '7_B',  # 25\n",
    "           '7_C',  # 26\n",
    "           '7_D',  # 27\n",
    "           '8_A',  # 28\n",
    "           '8_B',  # 29\n",
    "           '8_C',  # 30\n",
    "           '8_D')  # 31\n",
    "\n",
    "# unknown\n",
    "unknown_classes = ('9_A',  # 32\n",
    "                   '9_B',  # 33\n",
    "                   '9_C',  # 34\n",
    "                   '9_D',  # 35\n",
    "                   '10_A', # 36\n",
    "                   '10_B', # 37\n",
    "                   '10_C', # 38\n",
    "                   '10_D') # 39\n",
    "\n",
    "# # train, test, validation\n",
    "# classes = ('5_A',  # 16\n",
    "#            '5_B',  # 17\n",
    "#            '5_C',  # 18\n",
    "#            '5_D',  # 19\n",
    "#            '6_A',  # 20\n",
    "#            '6_B',  # 21\n",
    "#            '6_C',  # 22\n",
    "#            '6_D',  # 23\n",
    "#            '7_A',  # 24\n",
    "#            '7_B',  # 25\n",
    "#            '7_C',  # 26\n",
    "#            '7_D',  # 27\n",
    "#            '8_A',  # 28\n",
    "#            '8_B',  # 29\n",
    "#            '8_C',  # 30\n",
    "#            '8_D',  # 31\n",
    "#            '9_A',  # 32\n",
    "#            '9_B',  # 33\n",
    "#            '9_C',  # 34\n",
    "#            '9_D',  # 35\n",
    "#            '10_A', # 36\n",
    "#            '10_B', # 37\n",
    "#            '10_C', # 38\n",
    "#            '10_D') # 39\n",
    "\n",
    "# # unknown\n",
    "# unknown_classes = ('1_A',  # 0\n",
    "#                    '1_B',  # 1\n",
    "#                    '1_C',  # 2\n",
    "#                    '1_D',  # 3\n",
    "#                    '2_A',  # 4\n",
    "#                    '2_B',  # 5\n",
    "#                    '2_C',  # 6\n",
    "#                    '2_D',  # 7\n",
    "#                    '3_A',  # 8\n",
    "#                    '3_B',  # 9\n",
    "#                    '3_C',  # 10\n",
    "#                    '3_D',  # 11\n",
    "#                    '4_A',  # 12\n",
    "#                    '4_B',  # 13\n",
    "#                    '4_C',  # 14\n",
    "#                    '4_D')  # 15\n",
    "\n",
    "\n",
    "\n",
    "# test セットアップ\n",
    "num_classes = len(classes)\n",
    "embedding_size = 256\n",
    "\n",
    "# model読み込み\n",
    "model = HBM().to(device)\n",
    "load_model_path = './weights/checkpoint_fine_unknown_9_and_10_aug_10-data_model_20220205_200617.pth'\n",
    "load_model_weights = torch.load(load_model_path, map_location=device)\n",
    "model.load_state_dict(load_model_weights)\n",
    "\n",
    "# loss_func読み込み\n",
    "loss_func = ArcFaceLoss(num_classes, embedding_size).to(device)\n",
    "load_loss_func_path = './weights/checkpoint_fine_unknown_9_and_10_aug_10-data_loss_func_20220205_200617.pth'\n",
    "load_loss_func_weights = torch.load(load_loss_func_path, map_location=device)\n",
    "loss_func.load_state_dict(load_loss_func_weights)\n",
    "\n",
    "\n",
    "# ファイルパスのリストを作成 (test)\n",
    "# root_path = './data/'\n",
    "root_path = './data/unknown_9_and_10/'\n",
    "test_video_list = make_datapath_list(os.path.join(root_path, \"Test\"))\n",
    "\n",
    "\n",
    "# 前処理の設定\n",
    "resize = 96\n",
    "ccrop_size = 96\n",
    "rcrop_size = (96, 120)\n",
    "mean, std = [0.449], [0.226]\n",
    "# mean, std = [0.485, 0.456, 0.406], [0.229, 0.224, 0.225]\n",
    "video_transform = VideoTransform(resize, ccrop_size, rcrop_size, mean, std)\n",
    "\n",
    "\n",
    "# video_id label_id 辞書 (test)\n",
    "test_csv_path = os.path.join(root_path, \"Test.csv\")\n",
    "test_df = pd.read_csv(test_csv_path)\n",
    "test_videoid_labelid_dict = dict(test_df[[\"video_id\", \"label_id\"]].to_numpy())\n",
    "\n",
    "\n",
    "# データセットの作成\n",
    "test_dataset = VideoDataset(test_video_list, test_videoid_labelid_dict, num_segments=32,\n",
    "                           phase=\"val\", transform=video_transform, img_tmpl=\"{:05d}.jpg\", random_frame=False)\n",
    "\n",
    "\n",
    "# データローダーの作成\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=96, shuffle=False)\n",
    "\n",
    "\n",
    "\n",
    "# unknown セットアップ\n",
    "\n",
    "# ファイルパスのリストを作成 (unknown)\n",
    "# root_path = './data/'\n",
    "root_path = './data/unknown_9_and_10/'\n",
    "unknown_video_list = make_datapath_list(os.path.join(root_path, \"Unknown\"))\n",
    "\n",
    "\n",
    "# 前処理の設定\n",
    "resize = 96\n",
    "ccrop_size = 96\n",
    "rcrop_size = (96, 120)\n",
    "mean, std = [0.449], [0.226]\n",
    "# mean, std = [0.485, 0.456, 0.406], [0.229, 0.224, 0.225]\n",
    "video_transform = VideoTransform(resize, ccrop_size, rcrop_size, mean, std)\n",
    "\n",
    "\n",
    "# video_id label_id 辞書 (unknown)\n",
    "unknown_csv_path = os.path.join(root_path, \"Unknown.csv\")\n",
    "unknown_df = pd.read_csv(unknown_csv_path)\n",
    "unknown_videoid_labelid_dict = dict(unknown_df[[\"video_id\", \"label_id\"]].to_numpy())\n",
    "\n",
    "\n",
    "# データセットの作成\n",
    "unknown_dataset = VideoDataset(unknown_video_list, unknown_videoid_labelid_dict, num_segments=32,\n",
    "                               phase=\"val\", transform=video_transform, img_tmpl=\"{:05d}.jpg\", random_frame=False)\n",
    "\n",
    "\n",
    "# データローダーの作成\n",
    "unknown_dataloader = torch.utils.data.DataLoader(unknown_dataset, batch_size=120, shuffle=False)\n",
    "\n",
    "\n",
    "# FAR, FRR, EER, cos\n",
    "model.eval()\n",
    "W_cos = loss_func.state_dict()['W']\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_dataloader:\n",
    "        inputs, labels = [side_inputs.to(device) for side_inputs in inputs], labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        cosine = F.linear(F.normalize(outputs), F.normalize(W_cos.T))\n",
    "        \n",
    "        # EER test\n",
    "        x_p_test = cosine[torch.arange(labels.size(0)), labels].detach().cpu().numpy()\n",
    "        delete_index = [i*W_cos.size(1) + l for i, l in enumerate(labels.detach().cpu().numpy())]\n",
    "        x_n_test = np.delete(cosine.detach().cpu().numpy(), delete_index).reshape(-1)\n",
    "        \n",
    "        EER, EER_FAR, EER_FRR, EER_T, FAR_FRR_0, FAR_FRR_0_T, FRR_FAR_0, FRR_FAR_0_T = calculate_EER(x_p_test, x_n_test, data_group=\"test\")\n",
    "        display_info(EER, EER_FAR, EER_FRR, EER_T, FAR_FRR_0, FAR_FRR_0_T, FRR_FAR_0, FRR_FAR_0_T)\n",
    "\n",
    "print(\"____________________________________________________\")\n",
    "            \n",
    "with torch.no_grad():\n",
    "    for inputs, labels in unknown_dataloader:\n",
    "        inputs, labels = [side_inputs.to(device) for side_inputs in inputs], labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        cosine = F.linear(F.normalize(outputs), F.normalize(W_cos.T))\n",
    "        \n",
    "        # EER test and unknown\n",
    "        x_n_unknown = np.reshape(cosine.detach().cpu().numpy(), -1) \n",
    "        combined_x_n = np.concatenate([x_n_test, x_n_unknown])\n",
    "        \n",
    "        EER, EER_FAR, EER_FRR, EER_T, FAR_FRR_0, FAR_FRR_0_T, FRR_FAR_0, FRR_FAR_0_T = calculate_EER(x_p_test, combined_x_n, data_group=\"test_and_unknown\")\n",
    "        display_info(EER, EER_FAR, EER_FRR, EER_T, FAR_FRR_0, FAR_FRR_0_T, FRR_FAR_0, FRR_FAR_0_T)\n",
    "\n",
    "            \n",
    "test_pair = np.concatenate([x_p_test, x_n_test])\n",
    "fig, ax = plt.subplots()\n",
    "ax.hist(test_pair, bins=50, alpha=0.5, range=(-1, 1), label='test pair')\n",
    "ax.hist(x_n_unknown, bins=50, alpha=0.5, range=(-1, 1), label='unknown pair')\n",
    "ax.set_title('test pair and unknown pair')\n",
    "ax.set_xlabel('cos similarity')\n",
    "plt.legend(loc='upper left')\n",
    "date = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "outfile = 'cos_similarity_test_and_unknown_divided_{}.png'.format(date)\n",
    "plt.savefig(outfile)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84427253-8d0b-4de8-a371-c30345fac8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exp_3 unknown_1_to_4\n",
    "from utils.dataset import VideoDataset\n",
    "from utils.earlystopping import EarlyStopping\n",
    "from utils.function import make_datapath_list\n",
    "from utils.model import HBM\n",
    "from utils.transform import VideoTransform\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "\n",
    "from pytorch_metric_learning.losses import ArcFaceLoss\n",
    "\n",
    "# plt.rcParams['ps.useafm'] = True\n",
    "# plt.rcParams['pdf.use14corefonts'] = True\n",
    "# plt.rcParams['text.usetex'] = True\n",
    "\n",
    "# 乱数のシードを設定\n",
    "torch.manual_seed(1234)\n",
    "np.random.seed(1234)\n",
    "random.seed(1234)\n",
    "\n",
    "device = \"cuda:1\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# # train, test, validation\n",
    "# classes = ('1_A',  # 0\n",
    "#            '1_B',  # 1\n",
    "#            '1_C',  # 2\n",
    "#            '1_D',  # 3\n",
    "#            '2_A',  # 4\n",
    "#            '2_B',  # 5\n",
    "#            '2_C',  # 6\n",
    "#            '2_D',  # 7\n",
    "#            '3_A',  # 8\n",
    "#            '3_B',  # 9\n",
    "#            '3_C',  # 10\n",
    "#            '3_D',  # 11\n",
    "#            '4_A',  # 12\n",
    "#            '4_B',  # 13\n",
    "#            '4_C',  # 14\n",
    "#            '4_D',  # 15\n",
    "#            '5_A',  # 16\n",
    "#            '5_B',  # 17\n",
    "#            '5_C',  # 18\n",
    "#            '5_D',  # 19\n",
    "#            '6_A',  # 20\n",
    "#            '6_B',  # 21\n",
    "#            '6_C',  # 22\n",
    "#            '6_D',  # 23\n",
    "#            '7_A',  # 24\n",
    "#            '7_B',  # 25\n",
    "#            '7_C',  # 26\n",
    "#            '7_D',  # 27\n",
    "#            '8_A',  # 28\n",
    "#            '8_B',  # 29\n",
    "#            '8_C',  # 30\n",
    "#            '8_D')  # 31\n",
    "\n",
    "# # unknown\n",
    "# unknown_classes = ('9_A',  # 32\n",
    "#                    '9_B',  # 33\n",
    "#                    '9_C',  # 34\n",
    "#                    '9_D',  # 35\n",
    "#                    '10_A', # 36\n",
    "#                    '10_B', # 37\n",
    "#                    '10_C', # 38\n",
    "#                    '10_D') # 39\n",
    "\n",
    "# train, test, validation\n",
    "classes = ('5_A',  # 16\n",
    "           '5_B',  # 17\n",
    "           '5_C',  # 18\n",
    "           '5_D',  # 19\n",
    "           '6_A',  # 20\n",
    "           '6_B',  # 21\n",
    "           '6_C',  # 22\n",
    "           '6_D',  # 23\n",
    "           '7_A',  # 24\n",
    "           '7_B',  # 25\n",
    "           '7_C',  # 26\n",
    "           '7_D',  # 27\n",
    "           '8_A',  # 28\n",
    "           '8_B',  # 29\n",
    "           '8_C',  # 30\n",
    "           '8_D',  # 31\n",
    "           '9_A',  # 32\n",
    "           '9_B',  # 33\n",
    "           '9_C',  # 34\n",
    "           '9_D',  # 35\n",
    "           '10_A', # 36\n",
    "           '10_B', # 37\n",
    "           '10_C', # 38\n",
    "           '10_D') # 39\n",
    "\n",
    "# unknown\n",
    "unknown_classes = ('1_A',  # 0\n",
    "                   '1_B',  # 1\n",
    "                   '1_C',  # 2\n",
    "                   '1_D',  # 3\n",
    "                   '2_A',  # 4\n",
    "                   '2_B',  # 5\n",
    "                   '2_C',  # 6\n",
    "                   '2_D',  # 7\n",
    "                   '3_A',  # 8\n",
    "                   '3_B',  # 9\n",
    "                   '3_C',  # 10\n",
    "                   '3_D',  # 11\n",
    "                   '4_A',  # 12\n",
    "                   '4_B',  # 13\n",
    "                   '4_C',  # 14\n",
    "                   '4_D')  # 15\n",
    "\n",
    "\n",
    "# test セットアップ\n",
    "num_classes = len(classes)\n",
    "embedding_size = 256\n",
    "\n",
    "# model読み込み\n",
    "model = HBM().to(device)\n",
    "load_model_path = './weights/checkpoint_fine_unknown_1_to_4_aug_10-data_model_20220210_115641.pth'\n",
    "load_model_weights = torch.load(load_model_path, map_location=device)\n",
    "model.load_state_dict(load_model_weights)\n",
    "\n",
    "# loss_func読み込み\n",
    "loss_func = ArcFaceLoss(num_classes, embedding_size).to(device)\n",
    "load_loss_func_path = './weights/checkpoint_fine_unknown_1_to_4_aug_10-data_loss_func_20220210_115641.pth'\n",
    "load_loss_func_weights = torch.load(load_loss_func_path, map_location=device)\n",
    "loss_func.load_state_dict(load_loss_func_weights)\n",
    "\n",
    "\n",
    "# ファイルパスのリストを作成 (test)\n",
    "# root_path = './data/'\n",
    "root_path = './data/unknown_1_to_4/'\n",
    "test_video_list = make_datapath_list(os.path.join(root_path, \"Test\"))\n",
    "\n",
    "\n",
    "# 前処理の設定\n",
    "resize = 96\n",
    "ccrop_size = 96\n",
    "rcrop_size = (96, 120)\n",
    "mean, std = [0.449], [0.226]\n",
    "# mean, std = [0.485, 0.456, 0.406], [0.229, 0.224, 0.225]\n",
    "video_transform = VideoTransform(resize, ccrop_size, rcrop_size, mean, std)\n",
    "\n",
    "\n",
    "# video_id label_id 辞書 (test)\n",
    "test_csv_path = os.path.join(root_path, \"Test.csv\")\n",
    "test_df = pd.read_csv(test_csv_path)\n",
    "test_videoid_labelid_dict = dict(test_df[[\"video_id\", \"label_id\"]].to_numpy())\n",
    "\n",
    "\n",
    "# データセットの作成\n",
    "test_dataset = VideoDataset(test_video_list, test_videoid_labelid_dict, num_segments=32,\n",
    "                           phase=\"val\", transform=video_transform, img_tmpl=\"{:05d}.jpg\", random_frame=False)\n",
    "\n",
    "\n",
    "# データローダーの作成\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=72, shuffle=False)\n",
    "\n",
    "\n",
    "\n",
    "# unknown セットアップ\n",
    "\n",
    "# ファイルパスのリストを作成 (unknown)\n",
    "# root_path = './data/'\n",
    "root_path = './data/unknown_1_to_4/'\n",
    "unknown_video_list = make_datapath_list(os.path.join(root_path, \"Unknown\"))\n",
    "\n",
    "\n",
    "# 前処理の設定\n",
    "resize = 96\n",
    "ccrop_size = 96\n",
    "rcrop_size = (96, 120)\n",
    "mean, std = [0.449], [0.226]\n",
    "# mean, std = [0.485, 0.456, 0.406], [0.229, 0.224, 0.225]\n",
    "video_transform = VideoTransform(resize, ccrop_size, rcrop_size, mean, std)\n",
    "\n",
    "\n",
    "# video_id label_id 辞書 (unknown)\n",
    "unknown_csv_path = os.path.join(root_path, \"Unknown.csv\")\n",
    "unknown_df = pd.read_csv(unknown_csv_path)\n",
    "unknown_videoid_labelid_dict = dict(unknown_df[[\"video_id\", \"label_id\"]].to_numpy())\n",
    "\n",
    "\n",
    "# データセットの作成\n",
    "unknown_dataset = VideoDataset(unknown_video_list, unknown_videoid_labelid_dict, num_segments=32,\n",
    "                               phase=\"val\", transform=video_transform, img_tmpl=\"{:05d}.jpg\", random_frame=False)\n",
    "\n",
    "\n",
    "# データローダーの作成\n",
    "unknown_dataloader = torch.utils.data.DataLoader(unknown_dataset, batch_size=120, shuffle=False)\n",
    "\n",
    "\n",
    "# FAR, FRR, EER, cos\n",
    "model.eval()\n",
    "W_cos = loss_func.state_dict()['W']\n",
    "x_p_test = []\n",
    "x_n_test = []\n",
    "x_p_unknown = []\n",
    "x_n_unknown = []\n",
    "all_outputs = []\n",
    "all_labels = []\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_dataloader:\n",
    "        inputs, labels = [side_inputs.to(device) for side_inputs in inputs], labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        # EER test\n",
    "        for i in range(0, len(classes)):\n",
    "            for j in range(i, len(classes)):\n",
    "                cosine = F.linear(F.normalize(outputs[labels==i]), F.normalize(outputs[labels==j])).detach().cpu().numpy()\n",
    "                if i == j:\n",
    "                    cosine_positive = np.tril(cosine, k=-1)\n",
    "                    cosine_positive = cosine_positive[cosine_positive!=0]\n",
    "                    x_p_test.append(cosine_positive)\n",
    "                else:\n",
    "                    cosine_negative = np.reshape(cosine, -1)\n",
    "                    x_n_test.append(cosine_negative)\n",
    "        \n",
    "        x_p_test = np.reshape(np.array(x_p_test), -1)\n",
    "        x_n_test = np.reshape(np.array(x_n_test), -1)\n",
    "        \n",
    "        EER, EER_FAR, EER_FRR, EER_T, FAR_FRR_0, FAR_FRR_0_T, FRR_FAR_0, FRR_FAR_0_T = calculate_EER(x_p_test, x_n_test, data_group=\"test\")\n",
    "        display_info(EER, EER_FAR, EER_FRR, EER_T, FAR_FRR_0, FAR_FRR_0_T, FRR_FAR_0, FRR_FAR_0_T)\n",
    "\n",
    "print(\"____________________________________________________\")\n",
    "            \n",
    "with torch.no_grad():\n",
    "    for inputs, labels in unknown_dataloader:\n",
    "        inputs, labels = [side_inputs.to(device) for side_inputs in inputs], labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        all_outputs.append(outputs)\n",
    "        all_labels.append(labels)\n",
    "\n",
    "# print(len(all_outputs))\n",
    "# print(type(all_outputs))\n",
    "# print(len(all_labels))\n",
    "# print(type(all_labels))\n",
    "outputs = torch.cat(all_outputs)\n",
    "labels = torch.cat(all_labels)\n",
    "# print(outputs.shape)\n",
    "# print(type(outputs))\n",
    "# print(labels.shape)\n",
    "# print(type(labels))\n",
    "\n",
    "# outputs = outputs.view(-1)\n",
    "# labels = labels.view(-1)\n",
    "# print(outputs.shape)\n",
    "# print(type(outputs))\n",
    "# print(labels.shape)\n",
    "# print(type(labels))\n",
    "        \n",
    "# EER unknown\n",
    "for i in range(0, len(unknown_classes)):\n",
    "    if i < 8:\n",
    "        continue\n",
    "    for j in range(i, len(unknown_classes)):\n",
    "        if j < 8:\n",
    "            continue\n",
    "        cosine = F.linear(F.normalize(outputs[labels==i]), F.normalize(outputs[labels==j])).detach().cpu().numpy()\n",
    "        if i == j:\n",
    "            cosine_positive = np.tril(cosine, k=-1)\n",
    "            cosine_positive = cosine_positive[cosine_positive!=0]\n",
    "            x_p_unknown.append(cosine_positive)\n",
    "        else:\n",
    "            cosine_negative = np.reshape(cosine, -1)\n",
    "            x_n_unknown.append(cosine_negative)\n",
    "        \n",
    "x_p_unknown = np.reshape(np.array(x_p_unknown), -1)\n",
    "x_n_unknown = np.reshape(np.array(x_n_unknown), -1)\n",
    "        \n",
    "EER, EER_FAR, EER_FRR, EER_T, FAR_FRR_0, FAR_FRR_0_T, FRR_FAR_0, FRR_FAR_0_T = calculate_EER(x_p_unknown, x_n_unknown, data_group=\"unknown\")\n",
    "display_info(EER, EER_FAR, EER_FRR, EER_T, FAR_FRR_0, FAR_FRR_0_T, FRR_FAR_0, FRR_FAR_0_T)\n",
    "\n",
    "            \n",
    "# test_pair = np.concatenate([x_p_test, x_n_test])\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.hist(test_pair, bins=50, alpha=0.5, range=(-1, 1), label='test pair')\n",
    "# ax.hist(x_n_unknown, bins=50, alpha=0.5, range=(-1, 1), label='unknown pair')\n",
    "# ax.set_title('test pair and unknown pair')\n",
    "# ax.set_xlabel('cos similarity')\n",
    "# plt.legend(loc='upper left')\n",
    "# date = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "# outfile = 'cos_similarity_test_and_unknown_divided_{}.png'.format(date)\n",
    "# plt.savefig(outfile)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33d3456-27f5-43e7-94b0-92c3e35eea43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original を Train, Test, Validation, Unknown に分割\n",
    "# Originalと各フォルダを準備し、Unknownのindexを決める\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "from utils.function import make_datapath_list\n",
    "\n",
    "\n",
    "original_dir = './data/Original/'\n",
    "save_dir_path = './data/unknown_1_to_4/'\n",
    "\n",
    "if os.path.exists(original_dir):\n",
    "    # originalのファイルパスのリストを作成\n",
    "    original_list = make_datapath_list(original_dir)\n",
    "    \n",
    "    # original.csv読み込み\n",
    "    original_csv_path = './data/Original.csv'\n",
    "    original_df = pd.read_csv(original_csv_path)\n",
    "\n",
    "    \n",
    "    # train, test, validationのindexを取得\n",
    "    index = np.arange(len(original_list))\n",
    "    \n",
    "    # unknownのtarget_index\n",
    "#     unknown_target_index = [i for i in index if i>=0 and i<120]\n",
    "#     unknown_target_index = [i for i in index if i>=120 and i<240]\n",
    "#     unknown_target_index = [i for i in index if i>=240 and i<360]\n",
    "#     unknown_target_index = [i for i in index if i>=360 and i<480]\n",
    "#     unknown_target_index = [i for i in index if i>=480 and i<600]\n",
    "    unknown_target_index = [i for i in index if i>=0 and i<240]\n",
    "    print(unknown_target_index)\n",
    "    print(len(unknown_target_index))\n",
    "    \n",
    "    # known_indexを取得\n",
    "    known_index_mask = np.ones(len(original_list), dtype=bool)\n",
    "    known_index_mask[unknown_target_index] = False\n",
    "    known_index = index[known_index_mask]\n",
    "    print(known_index)\n",
    "    print(len(known_index))\n",
    "    \n",
    "    # unknown_indexを取得\n",
    "    unknown_index_mask = np.zeros(len(original_list), dtype=bool)\n",
    "    unknown_index_mask[unknown_target_index] = True\n",
    "    unknown_index = index[unknown_index_mask]\n",
    "    print(unknown_index)\n",
    "    print(len(unknown_index))\n",
    "    \n",
    "    # testのtarget_index\n",
    "    test_target_index = [i for i in known_index if i % 5 == 1]\n",
    "    print(test_target_index)\n",
    "    print(len(test_target_index))\n",
    "        \n",
    "    # validationのtarget_index\n",
    "    validation_target_index = [i for i in known_index if i % 5 == 3]\n",
    "    print(validation_target_index)\n",
    "    print(len(validation_target_index))\n",
    "    \n",
    "    # train_indexを取得\n",
    "    train_index_mask = np.ones(len(original_list), dtype=bool)\n",
    "    train_index_mask[unknown_target_index] = False\n",
    "    train_index_mask[test_target_index] = False\n",
    "    train_index_mask[validation_target_index] = False\n",
    "    train_index = index[train_index_mask]\n",
    "    print(train_index)\n",
    "    print(len(train_index))\n",
    "\n",
    "    # test_indexを取得\n",
    "    test_index_mask = np.zeros(len(original_list), dtype=bool)\n",
    "    test_index_mask[test_target_index] = True\n",
    "    test_index = index[test_index_mask]\n",
    "    print(test_index)\n",
    "    print(len(test_index))\n",
    "    \n",
    "    # validation_indexを取得\n",
    "    validation_index_mask = np.zeros(len(original_list), dtype=bool)\n",
    "    validation_index_mask[validation_target_index] = True\n",
    "    validation_index = index[validation_index_mask]\n",
    "    print(validation_index)\n",
    "    print(len(validation_index))\n",
    "    \n",
    "\n",
    "    # Train.csvの作成\n",
    "    train_df = original_df.iloc[train_index, :]\n",
    "    train_df.to_csv(os.path.join(save_dir_path, \"Train.csv\"), index=False)\n",
    "\n",
    "    # Test.csvの作成\n",
    "    test_df = original_df.iloc[test_index, :]\n",
    "    test_df.to_csv(os.path.join(save_dir_path, \"Test.csv\"), index=False)\n",
    "    \n",
    "    # Validation.csvの作成\n",
    "    validation_df = original_df.iloc[validation_index, :]\n",
    "    validation_df.to_csv(os.path.join(save_dir_path, \"Validation.csv\"), index=False)\n",
    "    \n",
    "    # Unknown.csvの作成\n",
    "    unknown_df = original_df.iloc[unknown_index, :]\n",
    "    unknown_df.to_csv(os.path.join(save_dir_path, \"Unknown.csv\"), index=False)\n",
    "\n",
    "    # Trainフォルダに移動\n",
    "    for video_id in train_df[\"video_id\"]:\n",
    "        path = original_dir + str(video_id) + '/'\n",
    "        shutil.move(path, os.path.join(save_dir_path, \"Train\"))\n",
    "\n",
    "    # Testフォルダに移動\n",
    "    for video_id in test_df[\"video_id\"]:\n",
    "        path = original_dir + str(video_id) + '/'\n",
    "        shutil.move(path, os.path.join(save_dir_path, \"Test\"))\n",
    "    \n",
    "    # Validationフォルダに移動\n",
    "    for video_id in validation_df[\"video_id\"]:\n",
    "        path = original_dir + str(video_id) + '/'\n",
    "        shutil.move(path, os.path.join(save_dir_path, \"Validation\"))\n",
    "        \n",
    "    # Unknownフォルダに移動\n",
    "    for video_id in unknown_df[\"video_id\"]:\n",
    "        path = original_dir + str(video_id) + '/'\n",
    "        shutil.move(path, os.path.join(save_dir_path, \"Unknown\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3efea4c8-9aea-4945-bb3b-a21ed36092e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# label_id を修正 train, test, validation\n",
    "# range を調整\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "original_dir = './data/unknown_1_to_4/'\n",
    "\n",
    "original_train_csv_path = os.path.join(original_dir, \"Train.csv\")\n",
    "original_train_df = pd.read_csv(original_train_csv_path)\n",
    "\n",
    "original_test_csv_path = os.path.join(original_dir, \"Test.csv\")\n",
    "original_test_df = pd.read_csv(original_test_csv_path)\n",
    "\n",
    "original_validation_csv_path = os.path.join(original_dir, \"Validation.csv\")\n",
    "original_validation_df = pd.read_csv(original_validation_csv_path)\n",
    "\n",
    "transformed_train_df = original_train_df\n",
    "transformed_test_df = original_test_df\n",
    "transformed_validation_df = original_validation_df\n",
    "\n",
    "for i in range(0, 24): # (0, 32), (8, 32), (16, 32), (24, 32), None\n",
    "#     transformed_train_df = transformed_train_df.replace({'label_id': {i+8: i}})\n",
    "#     transformed_test_df = transformed_test_df.replace({'label_id': {i+8: i}})\n",
    "#     transformed_validation_df = transformed_validation_df.replace({'label_id': {i+8: i}})\n",
    "    transformed_train_df = transformed_train_df.replace({'label_id': {i+16: i}})\n",
    "    transformed_test_df = transformed_test_df.replace({'label_id': {i+16: i}})\n",
    "    transformed_validation_df = transformed_validation_df.replace({'label_id': {i+16: i}})\n",
    "\n",
    "os.rename(os.path.join(original_dir, \"Train.csv\"), os.path.join(original_dir, \"Train_default.csv\")) \n",
    "transformed_train_df.to_csv(os.path.join(original_dir, \"Train.csv\"), index=False)\n",
    "os.rename(os.path.join(original_dir, \"Test.csv\"), os.path.join(original_dir, \"Test_default.csv\")) \n",
    "transformed_test_df.to_csv(os.path.join(original_dir, \"Test.csv\"), index=False)\n",
    "os.rename(os.path.join(original_dir, \"Validation.csv\"), os.path.join(original_dir, \"Validation_default.csv\")) \n",
    "transformed_validation_df.to_csv(os.path.join(original_dir, \"Validation.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04ac852-6290-4ac9-804a-c838b969d889",
   "metadata": {},
   "outputs": [],
   "source": [
    "# label_id を修正 unknown\n",
    "# range を調整\n",
    "import pandas as pd\n",
    "\n",
    "original_dir = './data/unknown_1_to_4/'\n",
    "\n",
    "original_unknown_csv_path = os.path.join(original_dir, \"Unknown.csv\")\n",
    "original_unknown_df = pd.read_csv(original_unknown_csv_path)\n",
    "transformed_unknown_df = original_unknown_df\n",
    "\n",
    "for i in range(0, 16):\n",
    "    transformed_unknown_df = transformed_unknown_df.replace({'label_id': {i+0: i}}) # 0, 8, 16, 24, 32\n",
    "\n",
    "os.rename(os.path.join(original_dir, \"Unknown.csv\"), os.path.join(original_dir, \"Unknown_default.csv\")) \n",
    "transformed_unknown_df.to_csv(os.path.join(original_dir, \"Unknown.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9badf079-8884-47c6-a82d-2229198dd0f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
