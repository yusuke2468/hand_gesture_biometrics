import numpy as np
import torch
from datetime import datetime

class EarlyStopping:
    """earlystoppingクラス"""

    def __init__(self, patience=5, verbose=False,
                 model_path='./weights/checkpoint_model_{}.pth'.format(datetime.now().strftime("%Y%m%d_%H%M%S")),
                 loss_func_path='./weights/checkpoint_loss_func_{}.pth'.format(datetime.now().strftime("%Y%m%d_%H%M%S"))):
        """引数：最小値の非更新数カウンタ、表示設定、モデル格納path"""

        self.patience = patience             #設定ストップカウンタ
        self.verbose = verbose               #表示の有無
        self.counter = 0                     #現在のカウンタ値
        self.best_score = None               #ベストスコア
        self.early_stop = False              #ストップフラグ
        self.val_loss_min = np.Inf           #前回のベストスコア記憶用
        self.model_path = model_path         #ベストモデル格納path
        self.loss_func_path = loss_func_path #ベストモデル格納path

    def __call__(self, val_loss, model, loss_func):
        """
        特殊(call)メソッド
        実際に学習ループ内で最小lossを更新したか否かを計算させる部分
        """
        score = -val_loss

        if self.best_score is None:  #1Epoch目の処理
            self.best_score = score   #1Epoch目はそのままベストスコアとして記録する
            self.checkpoint(val_loss, model, loss_func)  #記録後にモデルを保存してスコア表示する
        elif score < self.best_score:  # ベストスコアを更新できなかった場合
            self.counter += 1   #ストップカウンタを+1
            if self.verbose:  #表示を有効にした場合は経過を表示
                print(f'EarlyStopping counter: {self.counter} out of {self.patience}')  #現在のカウンタを表示する 
            if self.counter >= self.patience:  #設定カウントを上回ったらストップフラグをTrueに変更
                self.early_stop = True
        else:  #ベストスコアを更新した場合
            self.best_score = score  #ベストスコアを上書き
            self.checkpoint(val_loss, model, loss_func)  #モデルを保存してスコア表示
            self.counter = 0  #ストップカウンタリセット

    def checkpoint(self, val_loss, model, loss_func):
        '''ベストスコア更新時に実行されるチェックポイント関数'''
        if self.verbose:  #表示を有効にした場合は、前回のベストスコアからどれだけ更新したか？を表示
            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')
        torch.save(model.state_dict(), self.model_path)  #ベストモデルを指定したpathに保存
        torch.save(loss_func.state_dict(), self.loss_func_path)  #ベストモデルを指定したpathに保存
        self.val_loss_min = val_loss  #その時のlossを記録する